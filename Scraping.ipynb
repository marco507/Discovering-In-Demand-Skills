{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2aa1a4",
   "metadata": {},
   "source": [
    "## Job URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232aac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Scraping/jobs_listing.txt', 'r', encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = soup.find_all('a', class_='m-jobsListItem__titleLink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55382b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for job in jobs:\n",
    "    links.append(job.get('href'))\n",
    "    \n",
    "with open('Data/Scraping/jobs_url.csv', 'w') as file:\n",
    "    for link in links:\n",
    "        file.write(link)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e661e",
   "metadata": {},
   "source": [
    "## Job Listings HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ebcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_list = []\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    print(f'Scraping Job {i+1} of {len(links)}')\n",
    "    \n",
    "    success = False\n",
    "    \n",
    "    while not success:\n",
    "    \n",
    "        html = requests.get(link)\n",
    "        \n",
    "        if html.status_code == 200:\n",
    "            html_list.append(html.content)\n",
    "            success = True\n",
    "            \n",
    "        elif html.status_code == 404:\n",
    "            print('Site does not exist Error code 404')\n",
    "            success = True\n",
    "\n",
    "        elif html.status_code == 500:\n",
    "            print('Status Code 500 - Retry')\n",
    "\n",
    "        elif html.status_code == 502:\n",
    "            print('Status Code 502 - Retry')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0a687",
   "metadata": {},
   "source": [
    "## Job Listings Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = [str(html) for html in html_list]\n",
    "html = '\\n'.join(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find_all('div', class_='m-jobContent__jobText m-jobContent__jobText--standalone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0235ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, entry in enumerate(content):\n",
    "    with open(f'Data/Scraping/Jobs/job_{i+1}.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(entry.get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
